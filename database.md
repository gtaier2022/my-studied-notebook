<h3>database

<h5>mysql字符串设置

MySQL 字符编码集中有两套 UTF-8 编码实现：**`utf8`** 和 **`utf8mb4`**。

因此，如果你需要存储`emoji`类型的数据或者一些比较复杂的文字、繁体字到 MySQL 数据库的话，数据库的编码一定要指定为`utf8mb4` 而不是`utf8` ，要不然存储的时候就会报错了。

<h5>不推荐使用外键与级联

不得使用外键与级联，一切外键概念必须在应用层解决。

<h5>数据库范式了解吗

属性（对应于表中的字段）不能再被分割.

2NF 在 1NF 的基础之上，消除了非主属性对于码的部分函数依赖.

3NF：3NF 在 2NF 的基础之上，消除了非主属性对于码的传递函数依赖 。





<h5>drop、delete 与 truncate 区别

* drop(丢弃数据): `drop table 表名` ，直接将表都删除掉，在删除表的时候使用。
* truncate (清空数据) : `truncate table 表名` ，只删除表中的数据，再插入数据的时候自增长 id 又从 1 开始，在清空表中数据的时候使用。
* delete（删除数据） : `delete from 表名 where 列名=值`，删除某一行的数据，如果不加 where 子句和`truncate table 表名`作用类似。





<h5>数据库设计通常分为哪几步?

1.需求分析，

概念结构设计，采用E-R模型设计。

逻辑结构设计,将E-R图转换为表

物理结构设计:重要是设计数据库有的存储结构和存取路径。

数据库实施:包扣编程，测试，运行。

数据库的运行和维护。



<h5> SQL语句在MySQL中的执行过程
基础架构:

![Mysql基础架构](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/javaguide/13526879-3037b144ed09eb88.png)

连接器： 身份认证和权限相关(登录 MySQL 的时候)。

查询缓存： 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。

分析器：** 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。

优化器：** 按照 MySQL 认为最优的方案去执行。

执行器：** 执行语句，然后从存储引擎返回数据。 -



存储引擎**： 主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。**现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5 版本开始就被当做默认存储引擎了。



 MySQL中的**隐式转换**造成的**索引失效**

当操作符与不同类型的操作数一起使用时，会发生类型转换以使操作数兼容，MySQL会根据需要自动将字符串转换为数字。

通过上面的测试我们发现 MySQL 使用操作符的一些特性：

1. 当操作符**左右两边的数据类型不一致**时，会发生**隐式转换**。
2. 当 where 查询操作符**左边为数值类型**时发生了隐式转换，那么对效率影响不大，但还是不推荐这么做。
3. 当 where 查询操作符**左边为字符类型**时发生了隐式转换，那么会导致索引失效，造成全表扫描效率极低。
4. 字符串转换为数值类型时，非数字开头的字符串会转化为`0`，以数字开头的字符串会截取从第一个字符到第一个非数字内容为止的值为转化结果。

所以，我们在写 SQL 时一定要养成良好的习惯，查询的字段是什么类型，等号右边的条件就写成对应的类型。特别当查询的字段是字符串时，等号右边的条件一定要用引号引起来标明这是一个字符串，否则会造成索引失效触发全表扫描。



<h5>InnoDB存储引擎对MVCC的实现





<h5>MySQL高性能优化规范建议

数据库命名规范

1.所有数据库对象名必须使用小写字母并用下划线分割。

2.所有数据库对象名称禁止使用MySQL保留关键字。

数据库对象命名要呢个做到见起名，知其意。

临时表以tmp为前缀，并以日期为后缀，备份表必须以bar为前缀并以日期为后缀。

所有存储相同数据的列名和列类型必须一致。



数据库基本设计规范

1.所有表必须使用Innodb为存储引擎。

2.数据库和表的字符集统一使用UTF8

3.所有表和字段都需要添加注释。

4.经量控制单表数据量的大小，建议控制在500万以内。

5.谨慎使用MySQL分区表

6.尽量做到冷热数据分离，减少表的宽度。

7.禁止在表中建立预留字段。

8.禁止在数据库中存储图片，文件等大的二进制数据。

9.禁止在线上做数据库压力测试。

10.禁止从开发环境。测试环境直接连接生成环境数据库.



数据库字段设计规范。

1.优先选择符合存储需要的最小的数据类型。

2.避免使用TEXT,BLOB数据类型，最常见的TEXT类型可以存储64k的数据。

3.避免使用Enum类型。

4.尽可能把所有列定义为Not Null

5.使用时间戳或DATATIME类型存储时间。

6.同财务相关的金额类数据必须使用decimal类型。



索引设计规范

1.限制每一张表的索引数量上限不超过5个

2.静止给表中的每一列都建立单独的索引。

3.每个Innodb表必须有个主键。

4.常见的索引列建议。

- 出现在 SELECT、UPDATE、DELETE 语句的 WHERE 从句中的列

- 包含在 ORDER BY、GROUP BY、DISTINCT 中的字段

- 并不要将符合 1 和 2 中的字段的列都建立一个索引， 通常将 1、2 中的字段建立联合索引效果更好

- 多表 join 的关联列

  5.避免建立冗余索引和重复索引

6.对于频繁的查询优先考虑使用使用股改索引

7.尽量避免外键。[尽可能在业务代码中完成]



开发规范

1.尽量使用预编译语句进行数据库操作。

2.避免数据库类型的隐式转换。

3.充分利用表上已经存在的索引。

4.在数据库设计时，应该要对以后的拓展进行考虑。

5.程序连接不同的数据库使用不同的账号，禁止跨库查询。

6.禁止使用select*查询。

7.禁止使用不含字段列表的INSERT语句。

8.避免使用自查询，可以把子查询优化为操作。

9.避免使用join关联太多的表

10.禁止使用 order by rand() 进行随机排序

11.拆分复杂的大 SQL 为多个小 SQL



<h5>MySQL索引详解

索引是一种用于快速查询和检索数据的数据结构。常见的索引结构有: B 树， B+树和 Hash

hash表hash算法。

MyISAM和InnoDB

MyISAM非聚簇索引:key=>data域=>地址=>数据记录

InnoDB=>主索引搜索key=>data域=>数据记录

InnoDB=>在根据辅助索引查找时   辅索引=>key=>data域=>数据记录





索引类型:

主键索引[主键列]

二级索引辅助索引[主键的数据]

前缀索引，普通索引，唯一索引[二级索引]

全文索引[全文索引主要是为了检索大文本数据中的关键字信息]

聚集索引[表结构域数据一起存放的索引]

优点[查询的数据非常快]

缺点[更新代价大，依赖于有序的数据uuid 雪花算法都不是有序的]

非聚集索引[非聚集索引即索引结构和数据分开存放的索引。]

优点[更新代价比聚集索引要小]

缺点[依赖有序的数据，可能会二次查询] 

覆盖索引[索引包含所有需要查询的字段的值]

覆盖索引即需要查询的字段正好是索引的字段，那么直接根据该索引，就可以查到数据了，而无需回表查询。

联合索引[多个字段创建索引]

最左前缀匹配原则[在使用联合索引时]MySQL会根据联合索引中的字段顺序，从左到右依次到查询条件中去匹配。



创建索引的注意事项

1.不为null的字段

2.被频繁查询的字段

3.被作为条件的字段。

4.频繁需要排序的字段。

5.被经常频繁用连接的字段。

[被频繁更新的字段慎重新建索引]

[尽可能建立联合索引]

[避免冗余的索引]



使用索引建议[

1.对于中到大型表索引都是非常有效的，但是特大型表的话维护开销会很大，不适合建索引

2.避免 where 子句中对字段施加函数，这会造成无法命中索引。

3.在使用 InnoDB 时使用与业务无关的自增主键作为主键，即使用逻辑主键，而不要使用业务主键。

4.删除长期未使用的索引，

]







MySQL 如何为表字段添加索引？

主键索引

```sql
ALTER TABLE `table_name` ADD PRIMARY KEY ( `column` )
```

唯一索引

```sql
ALTER TABLE `table_name` ADD UNIQUE ( `column` )
```

普通索引

```sql
ALTER TABLE `table_name` ADD INDEX index_name ( `column` )
```

全文索引

```sql
ALTER TABLE `table_name` ADD FULLTEXT ( `column`)
```

联合索引

```sql
ALTER TABLE `table_name` ADD INDEX index_name ( `column1`, `column2`, `column3` )
```



<h5>MySQL事务隔离级别详解

事务：在逻辑上是一组操作，要么都执行，要么都不执行。

事务的ACID

并发事务导致的问题[脏读，丢失修改，不可重复读，幻读]

不可重复读与幻读的区别:

不可重复读的重点是修改，幻读的重点在于新增或者删除。

事务隔离级别

[读未提交] [脏读，幻读，不可重复读] 

[读已提交] [幻读，不可重复读] 

[可重复读] [幻读]

可串行化 [] 

脏读:当一个事务正在访问数据并对数据进行修改，而这种修改还没有提交到数据库中，另一个事务也访问了这个数据，然后使用这个数据[读未提交]

丢失修改:一个事务读取一个数据时，另一个事务也访问了该数据，第一个事务中修改这个数据后，第二个事务也修改了这个数据，这样第一个事务内的修改结果就被丢失

不可重复读:一个事务内多次读同一个数据，在这个事务还没有结束的时，另一个事务也访问了改数据。那么第一个事务中的两次数据之间，由于第二个事务的修改可能导致事务1读取两次的数据可能不太一样。

幻读:一个事务在读取几行数据，接着另一个并发事务插入了几条数据，在随后查询的中，第一个事务就会查询出多一些原本不存在的记录。

<h5>MySQL数据库时间类型数据存储建议

字符串存储日期的弊端:

1.字符串占用空间大。

2.字符串存储日期的效率低，无法用日期与相关的API之间进行计算和比较。

3.首选时间戳。[Datetime没有时区信息，切换时区会导致读时间出现错误 [Timestamp和时区有关] [DateTime 类型耗费空间更大]]

4.有时候也会采用int和bigint类型来表示时间戳[效率高，跨系统方便，但可读性查]





MyISAM 和InnoDB的对比

MyISAM :只支持表级锁InnoDB支持行级锁和表级锁，默认行级锁。

MyISAM :不支持事务，InnoDB支持事务，

InnoDB支持外键MyISAM：不支持[阿里巴巴开发手册中提到:禁止使用外键，外键的一切概念必须在应用层解决。]

是否支持 MVCC

MyISAM 不支持，而 InnoDB 支持。

是否支持数据库异常崩溃后的安全恢复[MyISAM 不支持，而 InnoDB 支持。]

是否支持 MVCC[MyISAM 不支持，而 InnoDB 支持。]

索引实现不一样[B+Tree，但是实现的方式不一样]



MySQL 查询缓存

在执行查询语句的时候，会先查询缓存，

开启查询缓存后在同样的查询条件以及数据情况下，会直接在缓存中返回结果。

查询缓存不命中的情况：

1.两个查询在任何字符上的不同都会导致缓存不命中，

2如果查询中包含任何用户自定义函数，存储函数，用户变量临时表，其查询的结果也不会被缓存。

3.表的结构或者数据发生变化，那么这张表和所有缓存都将失效。

4.会带来额外的开销



MySQL的隔离级别是基于锁实现的吗。

MySQL的隔离级别基于锁和MVCC机制实现的。

SERIALIZABLE 隔离级别，是通过锁来实现的，其余都是通过MVCC实现的。

其他隔离级别也要锁机制:[ REPEATABLE-READ [需要加锁避免幻读]]



MySQL 的默认隔离级别是什么?[可重读]



表级锁和行级锁了解吗

表级锁[一锁就锁整张表，并发写的情况下性能非常差,实现简单，资源消耗小，不会出现死锁，]。

对一行或者多行数据加锁，性能更高。

行级锁： MySQL 中锁定粒度最小的一种锁，是针对索引字段加的锁，只针对当前操作的记录进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。



行级锁使用的注意事项:

我们在执行update,delete 加where 进行条件筛选，where 字段没有命中索引，那么会扫描全表。



共享锁和排他锁呢

不论是表级锁还是行级锁，都存在共享锁（Share Lock，S 锁）和排他锁（Exclusive Lock，X 锁）这两类

共享锁（S 锁） ：又称读锁，事务在读取记录的时候获取共享锁，允许多个事务同时获取（锁兼容）。

排他锁（X 锁） ：又称写锁/独占锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条事务加任何类型的锁（锁不兼容）。

```sql
# 共享锁
SELECT ... LOCK IN SHARE MODE;
# 排他锁
SELECT ... FOR UPDATE;
```

InnoDB 有哪几类行锁？

MySQL InnoDB 支持三种行锁定方式：

- **记录锁（Record Lock）** ：也被称为记录锁，属于单个行记录上的锁。
- **间隙锁（Gap Lock）** ：锁定一个范围，不包括记录本身。
- **临键锁（Next-key Lock）** ：Record Lock+Gap Lock，锁定一个范围，包含记录本身。记录锁只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁。

InnoDB 的默认隔离级别 REPEATABLE-READ（可重读）是可以解决幻读问题发生的，主要有下面两种情况：

- **快照读** ：由 MVCC 机制来保证不出现幻读。
- **当前读** ： 使用 Next-Key Lock 进行加锁来保证不出现幻读。





<h5>日志

MySQL日志:错误日志，查询日志，慢查询日志，二进制日志。

属于二进制日日志[binlog归档日志] [redo log] (重做日志) undo log[回滚日志]





binlog[Server]归档日志[只要发生了表数据更新，都会产生 `binlog` 日志。] [记录内容是语句的原始逻辑]

binlog会记录所有涉及高性数据的逻辑操作，并且是顺序写。

记录格式

[statement] 记录sql语句原文。

![statement](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/02-20220305234738688.png)

[row] 

![](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/03-20220305234742460.png)

mixed:[折中] 会出现一致性问题用row 不会出现用statement

写入机制

`binlog`的写入时机也非常简单，事务执行过程中，先把日志写到`binlog cache`，事务提交的时候，再把`binlog cache`写到`binlog`文件中。







InnoDB存储引擎[undo log] 回滚日志

保证事务的原子性，就需要在异常发生时，对已经执行的操作进行**回滚**，在 MySQL 中，恢复机制是通过 **回滚日志（undo log）** 实现的

回滚机制会优先将数据持久化到磁盘。

可见性:mvcc实现依赖于隐藏字段、read view undo log 。在内部实现中，InnoDB通过数据行的DB_TRX_ID和Read View来判断数据的可见性， 如不可见,则通过数据行的DB_ROLL_PTR找到undolog中的历史版本，每一个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看见该事务创建Read View 之前已经提交的修改的改事务本身做的修改。



MySQL InnoDB 引擎使用 **redo log(重做日志)** 保证事务的**持久性**，使用 **undo log(回滚日志)** 来保证事务的**原子性**。

`MySQL`数据库的**数据备份、主备、主主、主从**都离不开`binlog`，需要依靠`binlog`来同步数据，保证数据一致性。



redo log(重做日志)它让mysql用有了恢复崩溃的能力。[恢复数据] [在某个数据页上做了什么修改]

请求=>Buffer pool =>硬盘=>Buffer pool=>undo log buffer => redo log



刷盘时机:

innodb_flush_log_at_trx_commit参数，它支持三种策略

0：每次事务提交时不进行刷盘操作。

1 ：设置为 1 的时候，表示每次事务提交时都将进行刷盘操作（默认值

2:设置为 2 的时候，表示每次事务提交时都只把 redo log buffer 内容写入 page cache

3.所以用 `redo log` 形式记录修改内容，性能会远远超过刷数据页的方式，这也让数据库的并发能力更强。





<h5>InnoDB存储引擎对MVCC的实现

MVCC的实现依赖于隐藏字段、Read View、undo log 。 在内部实现中，InnoDB通过行数据的 `DB_TRX_ID `和`Read View`字段来判断数据员的可见性，如不可见，则通过数据行的DB_ROLL_PTR找到undo log 中的历史版本。每一个事务读取大奥的数据版本可能是不一样的，在同一个事务中，用户只能看到改事务创建 `Read View` 之前已经提交的修改和改事务本身的修改。

隐藏字段

在内部，InnoDB存储引擎为每一行添加了三个隐藏字段。

DB_TRX_ID[插入更新]:事务id。删除时为更新，记录头[Record header]中的delete_flag字段将其标记为上传

DB_ROLL_PTR:回滚指针，指向undo log。如果改行为更新。则为空。

DB_ROW_ID：如果没有设置主键且该表没有唯一非空索引时，InnoDB会使用改id来生成聚簇索引。

Read View 主要是用来做可见性判断，里面保持了对本事务不可见的其他活跃事务。

m_low_limit_id：目前出现过的事务ID+1，即下一个被分配的事务ID:

m_up_limit_id:活跃事务列表m_ids中最小的事务id，如果m_ids为空，则m_up_limit_id为m_low_limit_id。小于这个ID的数据版本均不可见。

m_ids:Read View创建时其他未提交的活跃事务id列表。创建ReadView时，当前未提交的事务的ID记录下来。后续即使它们修改了记录行的值，对于当前事务也是不可见的，m_ids不包括当前事务和已提交事务。

m_creator_trx_id:创建该Read View 的事务id。



undo-log

作用:

当事务回滚时用将数据恢复到修改前的样子。

另一个作用MVCC使用，当读取记录时，若该记录被其他事务占用或当前版本对该事务不可见，则可以通过undo log读取之前的版本数据，以此实现非锁定读。

在InnoDB存储引擎中undo log分为两种: insert undolog 和update undo log ：

1.insert undo log 在insert操作中产生的undo log。因为插入操作的记录只对事务本身可见，对其它事务不可见，故undo log可在事务提交后直接删除，不需要进行purge操作。

2.update undo log:更新或者删除操作产生的undo log。该undo log可能需要提供MVCC机制{在发生错误的时候需要回滚}，因此不能在提交事务时就进行删除，提交时放入undo log链表中，等待整个事务完成{purge程序进行最后的删除}

3.不同事务或者是相同的事务对同一记录行的行修改，会使该记录行的undo log成为一条链表。链首是最新的记录，链尾是最早的记录。





数据可见性算法

创建一个新事务后，执行select语句前，都会产生一个快照，快照中保存了未提交事务id（m_ids）。

InnoDB会将Read View` 中的一些变量与DB_TRX_ID进行比较。





RC 和 RR 隔离级别下 MVCC 的差异

- 在 RC 隔离级别下的 **`每次select`** 查询前都生成一个`Read View` (m_ids 列表)
- 在 RR 隔离级别下只在事务开始后 **`第一次select`** 数据前生成一个`Read View`（m_ids 列表）



MVCC 解决不可重复读问题

- 在 RC 隔离级别下的 **`每次select`** 查询前都生成一个`Read View` (m_ids 列表)[好一些]
- 在 RR 隔离级别下只在事务开始后 **`第一次select`** 数据前生成一个`Read View`（m_ids 列表）



## MVCC➕Next-key-Lock 防止幻读

`InnoDB`存储引擎在 RR 级别下通过 `MVCC`和 `Next-key Lock` 来解决幻读问题：

**1、执行普通 `select`，此时会以 `MVCC` 快照读的方式读取数据**

在快照读的情况下，RR 隔离级别只会在事务开启后的第一次查询生成 `Read View` ，并使用至事务提交。所以在生成 `Read View` 之后其它事务所做的更新、插入记录版本对当前事务并不可见，实现了可重复读和防止快照读下的 “幻读”

**2、执行 select...for update/lock in share mode、insert、update、delete 等当前读**

在当前读下，读取的都是最新的数据，如果其它事务有插入新的记录，并且刚好在当前事务查询范围内，就会产生幻读！`InnoDB` 使用 [Next-key Lock](https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html#innodb-next-key-locks) 来防止这种情况。当执行当前读时，会锁定读取到的记录的同时，锁定它们的间隙，防止其它事务在查询范围内插入数据。只要我不让你插入，就不会发生幻读

<h5>Redis [做缓存][分布式锁][限流][消息队列]

缓存数据的处理流程是怎么样的

1. 如果用户请求的数据在缓存中就直接返回。
2. 缓存中不存在的话就看数据库中是否存在。
3. 数据库中存在的话就更新缓存中的数据。
4. 数据库中不存在的话就返回空数据。

Redis 常见数据结构

String[set,get,strlen,exists,decr,incr,setex]

list[rpush,lpop,lpush,rpop,lrange,llen] [双向链表]

hash[hset,hmset,hexists,hget,hgetall,hkeys,hvals]

set[sadd,spop,smembers,sismember,scard,sinterstore,sunion`]

sorted set[ `zadd,zcard,zscore,zrange,zrevrange,zrem`] [排序]

bitmap[`setbit` 、`getbit` 、`bitcount`、`bitop`]

Redis 线程模型[单线程]

1.[IO多路复用程序] [I/O多路复用技术的使用让Redis不需要额外建多余的线程来监听客户端的大量连接，降低资源消耗]。

Redis6.0 的多线程默认是禁用的

```bash
io-threads-do-reads yes
```

开启多线程后，还需要设置线程数，否则是不生效的。同样需要修改 redis 配置文件 `redis.conf` 

```bash
io-threads 4
```

redis数据过期

Redis 中除了字符串类型有自己独有设置过期时间的命令 `setex` 外，其他方法都需要依靠 `expire` 命令来设置过期时间 。另外， `persist` 命令可以移除一个键的过期时间。

过期策略[惰性删除和定期删除]

惰性删除，只会在取出key值的时候才对数据进行过期检查。

定期删除:每隔一段时间就抽取一批key执行过期key存在。

定期删除删除对内存友好，惰性删除对cpu友好，

cpu采用定期删除+惰性/懒汉式删除。



Redis内存淘汰机制。

valatile-lru：从设置过期时间的数据中挑选最少使用的数据淘汰，

volatile--ttl：要过期的数据淘汰

volatile-random：任意选择数据淘汰。

allkeys-lru：内存不足以容纳新写入数据时，在键空间中，移除最近使用最少的key。

allkeys-random：从数据集中任意选择数据淘汰。

no-eviction：禁止驱除数据。

volatile-lfu：从已设置过期时间的数据集，挑选最不经常使用的数据淘汰。

allkeys-lfu:当内存不足时，在键空间移除最不经常使用的key。





Redis持久化机制:

Redis的一种持久化方式的快照(RDB)另一种只追加文件(AOF)

持久化快照是Redis默认持久化方式。

```clojure
save 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。

save 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。

save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
```

AOF：

AOF是实时性更好，

可以通过appendonly参数开启

```conf
appendonly yes
```

一般是选1s对性能无影响，也只会丢1s的数据

```conf
appendfsync always    #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度
appendfsync everysec  #每秒钟同步一次，显式地将多个写命令同步到硬盘
appendfsync no        #让操作系统决定何时进行同步
```

AOF 重写

```bash
BGREWRITEAOF
```



RDB 和 AOF混合开启配置

```conf
aof-use-rdb-preamble 
```



Redis事务

Redis可以通过MULTI[开始事务]，EXEC[执行事务]，DISCARD[取消一个事务]和WATCH[监听指定键]等命令来实现事务功能

Redis 事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断

Redis支持原子性吗?[不支持原子性[不能回滚]，不满足持久性[宕机数据就没有了]]

```

```

Redis性能优化:

bigkey[key对应的value所占用的内存比较大[10k]] [消耗内存空间，对性能影响大]

大量 key 集中**过期**问题[设置key的**随机过期时间**。开启lazy-free（惰性删除/延迟是否）]

缓存穿透[做好参数校验,缓存无效key] [布隆过滤器]]

缓存雪崩[缓存在同一时间大面积的**失效**，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求] [Redis 集群，限流，[热点数据用不失效]]



3种常用的缓存读写策略

旁路缓存模式：

**写** ：[不可以换步骤造成数据库于缓存数据的不一致] [缓存的写入速度比数据库的写入速度快很多]]

- 先更新 DB
- 然后直接删除 cache 。

**读** :

- 从 cache 中读取数据，读取到就直接返回
- cache中读取不到的话，就从 DB 中读取数据返回
- 再把数据放到 cache 中。

读写穿透:

写：

先查 cache，cache 中不存在，直接更新 DB。

cache 中存在，则先更新 cache，然后 cache 服务自己更新 DB（**同步更新 cache 和 DB**）。

读(Read Through)：

从 cache 中读取数据，读取到就直接返回 。

读取不到的话，先从 DB 加载，写入到 cache 后返回响应。

异步缓存写入[存在数据一致性问题] [业务:浏览量，点赞量]

两者都是由 cache 服务来负责 cache 和 DB 的读写 Read/Write Through 是同步更新 cache 和 DB，而 Write Behind Caching 则是只更新缓存，不直接更新 DB，而是改为异步批量的方式来更新 DB。



 Redis 内存碎片[info memory查看]

产生原因:

1.Redis 存储存储数据的时候向操作系统申请的内存空间可能会大于数据实际需要的存储空间

2.频繁修改 Redis 中的数据也会产生内存碎片



如何清理 Redis 内存碎片？

[config set activedefrag yes]
